&&&& RUNNING TensorRT.trtexec [TensorRT v8201] # /usr/src/tensorrt/bin/trtexec --loadEngine=resnet50_pytorch.trt --batch=1
[03/29/2023-22:57:41] [I] === Model Options ===
[03/29/2023-22:57:41] [I] Format: *
[03/29/2023-22:57:41] [I] Model: 
[03/29/2023-22:57:41] [I] Output:
[03/29/2023-22:57:41] [I] === Build Options ===
[03/29/2023-22:57:41] [I] Max batch: 1
[03/29/2023-22:57:41] [I] Workspace: 16 MiB
[03/29/2023-22:57:41] [I] minTiming: 1
[03/29/2023-22:57:41] [I] avgTiming: 8
[03/29/2023-22:57:41] [I] Precision: FP32
[03/29/2023-22:57:41] [I] Calibration: 
[03/29/2023-22:57:41] [I] Refit: Disabled
[03/29/2023-22:57:41] [I] Sparsity: Disabled
[03/29/2023-22:57:41] [I] Safe mode: Disabled
[03/29/2023-22:57:41] [I] DirectIO mode: Disabled
[03/29/2023-22:57:41] [I] Restricted mode: Disabled
[03/29/2023-22:57:41] [I] Save engine: 
[03/29/2023-22:57:41] [I] Load engine: resnet50_pytorch.trt
[03/29/2023-22:57:41] [I] Profiling verbosity: 0
[03/29/2023-22:57:41] [I] Tactic sources: Using default tactic sources
[03/29/2023-22:57:41] [I] timingCacheMode: local
[03/29/2023-22:57:41] [I] timingCacheFile: 
[03/29/2023-22:57:41] [I] Input(s)s format: fp32:CHW
[03/29/2023-22:57:41] [I] Output(s)s format: fp32:CHW
[03/29/2023-22:57:41] [I] Input build shapes: model
[03/29/2023-22:57:41] [I] Input calibration shapes: model
[03/29/2023-22:57:41] [I] === System Options ===
[03/29/2023-22:57:41] [I] Device: 0
[03/29/2023-22:57:41] [I] DLACore: 
[03/29/2023-22:57:41] [I] Plugins:
[03/29/2023-22:57:41] [I] === Inference Options ===
[03/29/2023-22:57:41] [I] Batch: 1
[03/29/2023-22:57:41] [I] Input inference shapes: model
[03/29/2023-22:57:41] [I] Iterations: 10
[03/29/2023-22:57:41] [I] Duration: 3s (+ 200ms warm up)
[03/29/2023-22:57:41] [I] Sleep time: 0ms
[03/29/2023-22:57:41] [I] Idle time: 0ms
[03/29/2023-22:57:41] [I] Streams: 1
[03/29/2023-22:57:41] [I] ExposeDMA: Disabled
[03/29/2023-22:57:41] [I] Data transfers: Enabled
[03/29/2023-22:57:41] [I] Spin-wait: Disabled
[03/29/2023-22:57:41] [I] Multithreading: Disabled
[03/29/2023-22:57:41] [I] CUDA Graph: Disabled
[03/29/2023-22:57:41] [I] Separate profiling: Disabled
[03/29/2023-22:57:41] [I] Time Deserialize: Disabled
[03/29/2023-22:57:41] [I] Time Refit: Disabled
[03/29/2023-22:57:41] [I] Skip inference: Disabled
[03/29/2023-22:57:41] [I] Inputs:
[03/29/2023-22:57:41] [I] === Reporting Options ===
[03/29/2023-22:57:41] [I] Verbose: Disabled
[03/29/2023-22:57:41] [I] Averages: 10 inferences
[03/29/2023-22:57:41] [I] Percentile: 99
[03/29/2023-22:57:41] [I] Dump refittable layers:Disabled
[03/29/2023-22:57:41] [I] Dump output: Disabled
[03/29/2023-22:57:41] [I] Profile: Disabled
[03/29/2023-22:57:41] [I] Export timing to JSON file: 
[03/29/2023-22:57:41] [I] Export output to JSON file: 
[03/29/2023-22:57:41] [I] Export profile to JSON file: 
[03/29/2023-22:57:41] [I] 
[03/29/2023-22:57:41] [I] === Device Information ===
[03/29/2023-22:57:41] [I] Selected Device: NVIDIA Tegra X1
[03/29/2023-22:57:41] [I] Compute Capability: 5.3
[03/29/2023-22:57:41] [I] SMs: 1
[03/29/2023-22:57:41] [I] Compute Clock Rate: 0.9216 GHz
[03/29/2023-22:57:41] [I] Device Global Memory: 3963 MiB
[03/29/2023-22:57:41] [I] Shared Memory per SM: 64 KiB
[03/29/2023-22:57:41] [I] Memory Bus Width: 64 bits (ECC disabled)
[03/29/2023-22:57:41] [I] Memory Clock Rate: 0.01275 GHz
[03/29/2023-22:57:41] [I] 
[03/29/2023-22:57:41] [I] TensorRT version: 8.2.1
[03/29/2023-22:57:43] [I] [TRT] [MemUsageChange] Init CUDA: CPU +230, GPU +0, now: CPU 370, GPU 2537 (MiB)
[03/29/2023-22:57:43] [I] [TRT] Loaded engine size: 121 MiB
[03/29/2023-22:57:45] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +158, GPU +159, now: CPU 528, GPU 2696 (MiB)
[03/29/2023-22:57:47] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +241, GPU +241, now: CPU 769, GPU 2937 (MiB)
[03/29/2023-22:57:47] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +121, now: CPU 0, GPU 121 (MiB)
[03/29/2023-22:57:47] [I] Engine loaded in 5.63681 sec.
[03/29/2023-22:57:47] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 647, GPU 2816 (MiB)
[03/29/2023-22:57:47] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +0, now: CPU 647, GPU 2816 (MiB)
[03/29/2023-22:57:47] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +334, now: CPU 0, GPU 455 (MiB)
[03/29/2023-22:57:47] [I] Using random values for input input.1
[03/29/2023-22:57:49] [I] Created input binding for input.1 with dimensions 32x3x224x224
[03/29/2023-22:57:49] [I] Using random values for output 495
[03/29/2023-22:57:49] [I] Created output binding for 495 with dimensions 32x1000
[03/29/2023-22:57:49] [I] Starting inference
[03/29/2023-22:58:15] [I] Warmup completed 1 queries over 200 ms
[03/29/2023-22:58:15] [I] Timing trace has 10 queries over 24.3831 s
[03/29/2023-22:58:15] [I] 
[03/29/2023-22:58:15] [I] === Trace details ===
[03/29/2023-22:58:15] [I] Trace averages of 10 runs:
[03/29/2023-22:58:15] [I] Average on 10 runs - GPU latency: 2436.29 ms - Host latency: 2438.3 ms (end to end 2438.31 ms, enqueue 3.85515 ms)
[03/29/2023-22:58:15] [I] 
[03/29/2023-22:58:15] [I] === Performance summary ===
[03/29/2023-22:58:15] [I] Throughput: 0.41012 qps
[03/29/2023-22:58:15] [I] Latency: min = 2366.36 ms, max = 2514.21 ms, mean = 2438.3 ms, median = 2433.33 ms, percentile(99%) = 2514.21 ms
[03/29/2023-22:58:15] [I] End-to-End Host Latency: min = 2366.37 ms, max = 2514.22 ms, mean = 2438.31 ms, median = 2433.34 ms, percentile(99%) = 2514.22 ms
[03/29/2023-22:58:15] [I] Enqueue Time: min = 1.74588 ms, max = 4.4043 ms, mean = 3.85515 ms, median = 4.09668 ms, percentile(99%) = 4.4043 ms
[03/29/2023-22:58:15] [I] H2D Latency: min = 1.88037 ms, max = 2.29932 ms, mean = 1.99302 ms, median = 1.98145 ms, percentile(99%) = 2.29932 ms
[03/29/2023-22:58:15] [I] GPU Compute Time: min = 2364.04 ms, max = 2512.25 ms, mean = 2436.29 ms, median = 2431.36 ms, percentile(99%) = 2512.25 ms
[03/29/2023-22:58:15] [I] D2H Latency: min = 0.0117188 ms, max = 0.0136719 ms, mean = 0.0134277 ms, median = 0.0136719 ms, percentile(99%) = 0.0136719 ms
[03/29/2023-22:58:15] [I] Total Host Walltime: 24.3831 s
[03/29/2023-22:58:15] [I] Total GPU Compute Time: 24.3629 s
[03/29/2023-22:58:15] [I] Explanations of the performance metrics are printed in the verbose logs.
[03/29/2023-22:58:15] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8201] # /usr/src/tensorrt/bin/trtexec --loadEngine=resnet50_pytorch.trt --batch=1
